We thank the reviewer for their thoughtful comments and suggestions. Below, we
address each of the main concerns raised.

1. Mistakes due to unreliable CI tests.

It is true that the mistakes made by constraint-based causal discovery arise
due to difficulties in CI testing. Our approach aims to exactly tackle this
issue by involving the expert in the model building process and not rely solely
on the CI tests. Our approach utilizes CI tests and measures of association
(effect size measures of these CI tests) to identify and rank potential
modifications to the DAG. The user can then use this information to make an
informed choice of the most suitable modification to the model. Previously, it
has been shown that integrating expert knowledge in causal discovery can
improve the results of automated algorithms [1][2], we present an interactive
way to specify this expert knowledge. This interactive approach allows the user
to be fully in control (and hence avoid the mistakes made by CI tests) while
still being able to use information from the data through CI tests to make
their decisions.

2. Lack of theoretical analysis under imperfect expert knowledge.

We acknowledge the importance of understanding how the method behaves when
expert knowledge is imperfect. However, as with many causal discovery
algorithms, formal theoretical guarantees (such as correctness) generally
require strong assumptions, such as access to a perfect CI test oracle (as in
PC algorithm) or a consistent scoring function (as in score-based approaches).

In our case, we similarly assume access to an ancestral oracle and a
d-separation oracle to prove correctness of our method. And to evaluate
violations of these assumptions, we provide empirical analysis under various
scenarios including varying levels of expert accuracy. We will clarify the
limitations of our theoretical analysis in the paper.

3. Use of residual association for prioritizing DAG modifications.

The residual association is an effect size measure for the CI test. For a CI
test, $ X \ci Y | \bm{Z} $, the residual association quantifies the strength of
association between $ X $ and $ Y $ after conditioning on $ \bm{Z} $. Hence, if
a CI statement is true, the conditional association value would be close to $ 0
$. In our setting, given a DAG $ G $, we select pair of variables $ X $ and $ Y
$ with $ \bm{Z} = pa_G(X) \cup pa_G(Y) $, and compute the conditional
association between $ X $ and $ Y $. Here, the conditional association
quantifies how much of the observed association between $ X $ and $ Y $ in the
data is not explained by $ G $. If $ G $ is able to fully explain the observed
association, the CI test would be true and the conditional association would be
close to $ 0 $ (from Causal Markov Condition and Faithfulness). Hence, we can
use this conditional association measures to rank CI tests based on how severe
the violation is.

While this interpretation is discussed a bit in Section 3.1, we will make it
more explicit in Section 3.2.

4. Issues in text.
Thank you for pointing these out, we will fix them.

[1] Meek, Christopher. "Causal inference and causal explanation with background knowledge." In Proceedings of the Eleventh conference on Uncertainty in artificial intelligence (UAI'95). 
[2] Bang, Christine W., and Vanessa Didelez. "Do we become wiser with time? On causal equivalence with tiered background knowledge." Uncertainty in Artificial Intelligence. PMLR, 2023.
