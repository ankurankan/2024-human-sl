The comparisons between different algorithms in the simulation study and the real data example are difficult to interpret since they output vastly different numbers of edges (due to arbitrarily set hyperparameters). It would be much simpler to follow the discussion of Figure 1 and Sections 4-5 if they were tuned to output the same number of edges (Petersen, Ekstrøm, Spirtes and Osler 2023).

I find the handling of edges leading to cyclicity in Algorithm 1 problematic (reversing an edge imposed by an expert). This will induce very strong causal statements that the experts do specifically not support. Is it possible to modify the algorithm (Algorithm 1) to instead skip such edges? Or perhaps prompt experts to reconsider other edge modifications that may remove the cycle?

There is no description of what happens if the procedure is stopped before it ends "naturally". I think this is quite an important case, as an expert might at some point (correctly) conclude that they do not have knowledge about the remaining candidate edges. Is there a way to process the remainding information to ensure a sound (but possibly incomplete) output in this case?

Using data to learn the graph with a human in the loop obviously induces post-selection inference issues if the same data is afterwards used for effect estimation/causal inference. This should be warned explicitly in the paper, as experts may otherwise think they get a free lunch in using their data for this. The cost is high and cannot simply routinely be applied without taking this into account (but likely worth it in many cases!).

The descriptions of conditional independence tests are not as general as they are presented. In the case where both X and Y are continuous, there is an implicit assumption of Gaussianity; otherwise the Pearson correlation does not generally test independence. In the case where X is ordinal and Y or Z are ordinal or continuous, I suspect that it is also needed to assume that the continuous variables are Gaussian in order to obtain a test of conditional independence. Finally, the case of mixed continuous and nominal categorical data is missing.

References: Petersen, A. H., Ekstrøm, C. T., Spirtes, P., & Osler, M. (2023). Constructing causal life-course models: comparative study of data-driven and theory-driven approaches. American Journal of Epidemiology, 192(11), 1917-1927.

Introduction: "Age" is mentioned as an obviously unmodifiable factor. I do not think this is the best example; in many studies age can meaningfully be endogenous as it is age at enrolment in the study (e.g. "age at diagnosis").
Introduction: On p. 2, it is noted that experts do not need to distinguish between direct and indirect effects. But what if some experts do in fact want to do this? For example, some areas of social science and epidemiology has been greatly concerned with mediation analyses and hence experts from these fields may in some cases have strong opinions that are not only ancestral. Is it possible for them to express this knowledge? And how are the edges shown in the GUI (Figure 7) to be interpreted? As far as I understand, they describe the transitive closure of the "current" DAG estimate. I would be worried that some experts may misinterpret it as evidence for direct causal effects.
As far as I understand, it is not possible for experts to overrule statistical statements and e.g. insist on edge presence that is not supported by the data. I think this is a limitation of real usecases, as conditional independence testing is error-prone on finite data, and that especially near-violations of faithfulness can cause issues. It would be very useful if the authors could provide a discussion comment about whether it would be feasible to extend the algorithm to allow for this (i.e., explore the case of a faulty conditional independence oracle).
Section 3.3: It could perhaps be useful to note that the "score" tau is not score-equivalent either, as members of the same MEC will get different tau values.
In the simulation study, the authors find that expert knowledge is especially useful when the graphs are dense, which is not very surprising, as the considered algorithms are well-known to struggle in this setting. It would be interesting to also see comparisons to algorithms like GRaSP or BOSS, which seem to be stronger on dense graphs.
Section 4: "Unlike EXPERTINLOOP, the automated algorithms can only recover the MEC". Although this is true for the considered algorithms, this specific data simulation design does lead to one of the special cases where the DAG is indeed identifiable (due to the Gaussianity with equal errors). I do not think it is interesting to consider the implications of this special case in the simulation study, but to lessen confusion, it should be mentioned.
Section 4: "implying that if an expert is able to get the edge orientation correctly in more than 1 out of 2 cases,". Is it only edge orientation? An (imperfect) strong ancestral oracle is used, and hence it must also include edge absence.
Algorithm 1: a. I found it difficult to follow what information was from the true graph/conditional independence oracle, and what was the current version, and it took me some time to realize that E is not updated until the end. Please consider mentioning this in the text. b. I find the assignment "e <- ..." in line 6 and the following operations on "e" (including "rev(e)") a bit misleading, as "e" may be "none". c. I do not understand l. 14. Shouldn't it go to line 17 rather than 12? d. I do not understand why l. 13-15 are not included in the if-statement starting in l. 5. If D_G(X, Y, Z) != 0, nothing is added, and hence it makes no sense to do the check.
